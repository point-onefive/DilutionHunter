Perfect â€” so here's what I'll do:

### ğŸ”¥ Iâ€™ll give you BOTH:

1. **A fully expanded Copilot prompt**
   (that you paste into your repo or Cursor side panel â€” the â€œmaster instruction setâ€ for the entire build)

2. **Starter code + file structure**
   so Copilot has scaffolding and context to generate the REST automatically

You will literally be able to paste this into your repository **TODAY** and GitHub + Copilot can build iteratively from it.

---

# ğŸ“Œ **STEP 1 â€” MASTER PROMPT FOR COPILOT**

Paste this in **README.md** AND as a **/docs/system.md** so Copilot *always remembers the objective.*

---

### **ğŸ”· Copilot â€” System Build Instructions ğŸ”·**

```
You are assisting in building a full automated stock dilution risk scanner + X/Twitter posting engine.

Goal:
Run a job 1â€“3 times per day (GitHub Actions CRON). 
Scan the entire US market for parabolic movers (small-cap/microcap preferred), detect dilution offering risk, generate human-like tweet threads via OpenAI, store only tickers that trigger signals, then track their performance daily and post updates.

Data Source: Financial Modeling Prep (FMP API)
Required endpoints:
  1. Full symbol list (NYSE, NASDAQ, AMEX, microcaps)
  2. OHLCV historical candles (daily)
  3. Weekly % change
  4. Balance sheet: cash, total debt
  5. Cashflow: burn rate
  6. Equity Offerings API: ATM, shelf, deal size, date filed

Trigger Criteria (all must be true for a stock to be flagged):
  - 200â€“300%+ increase in 7 days (configurable threshold)
  - Volume blow-off top followed by decline
  - Bearish candle or first red day after parabolic move
  - Low cash vs debt OR negative cashflow runway
  - Equity offering present â€” preferably large relative to market cap

When triggered:
  - Create or update `active_signals.json` file
  - Store: ticker, trigger_date, trigger_price, offering_amount, cash, debt,
    reason, confidence_score, and relevant supporting details
  - Call OpenAI API to generate a tweet thread summary
  - Auto-post to Twitter/X using Premium X API credentials
  - Add ticker to `performance_history.json` for follow-up tracking

Daily follow-ups:
  - For each tracked ticker, fetch latest close price
  - Update performance log in `performance_history.json`
  - Generate follow-up tweet summarizing P/L progression

Architecture Requirements:
  - No database required â€” store JSON local and commit back to repository
  - Two tracking buckets:
        1. active_signals.json (tickers currently monitored)
        2. performance_history.json (progress after trigger)
  - GitHub Actions runs scanner + follow-up scripts
  - Everything must run headless, stateless except JSON persistence
  - Code must be modular + expandable

Deliverables Copilot must produce:
  âœ” `/src/scanner.js` â€” pull universe + detect triggers
  âœ” `/src/scoreEngine.js` â€” logic for qualification + scoring
  âœ” `/src/storage.js` â€” reads/writes JSON state
  âœ” `/src/postTweet.js` â€” calls OpenAI â†’ generates thread â†’ posts to X
  âœ” `/src/updatePerformance.js` â€” updates tracked tickers daily
  âœ” `/.github/workflows/scan.yml` â€” scheduled scan job
  âœ” `/docs/architecture.md` â€” summary of system decisions

Everything must be built iteratively.
Copilot should ask for clarification when needed.
```

---

# ğŸ“Œ STEP 2 â€” FOLDER STRUCTURE TO CREATE NOW

Create these empty files so Copilot can fill them:

```
/src/scanner.js
/src/scoreEngine.js
/src/postTweet.js
/src/storage.js
/src/updatePerformance.js

/data/active_signals.json
/data/performance_history.json

/docs/architecture.md
README.md

/.github/workflows/scan.yml
/.env (ignored)
```

Add this to `.gitignore`:

```
.env
node_modules
```

---

# ğŸ“Œ STEP 3 â€” Hereâ€™s Your **Starter Code** to Seed Copilot

### `/src/scanner.js` (Copilot will expand this aggressively)

```js
import { getSymbols, getWeeklyChange, getFinancials, getOfferings, getOHLCV } from "./vendors/fmp.js";
import { evaluateSignal } from "./scoreEngine.js";
import { loadSignals, saveSignals } from "./storage.js";
import { postTweet } from "./postTweet.js";

export async function runScan() {
  const activeSignals = loadSignals();
  const universe = await getSymbols();   // all US tickers

  for (const ticker of universe) {
    const metrics = await getWeeklyChange(ticker);
    if (metrics.weeklyChange < 200) continue;

    const fundamentals = await getFinancials(ticker);
    const offerings = await getOfferings(ticker);
    const candles = await getOHLCV(ticker, 30);

    const decision = evaluateSignal({ticker, metrics, fundamentals, offerings, candles});
    if (!decision.shouldTrigger) continue;

    activeSignals.push(decision);
    await postTweet(decision);  // â­ AI formatted thread
  }

  saveSignals(activeSignals);
}

runScan();
```

---

### `/src/scoreEngine.js`

```js
export function evaluateSignal({ticker, metrics, fundamentals, offerings, candles}) {
  const redDay = candles[candles.length-1].close < candles[candles.length-1].open;
  const volumeDrop = candles[candles.length-1].volume < candles[candles.length-2].volume;
  const lowCash = fundamentals.cash < fundamentals.debt;

  const hasOffering = offerings && offerings.size > 0;

  const shouldTrigger =
    metrics.weeklyChange > 250 &&
    redDay &&
    volumeDrop &&
    lowCash &&
    hasOffering;

  return {
    ticker,
    shouldTrigger,
    fundamentals,
    offerings,
    metrics,
    score: Number(shouldTrigger),
    timestamp: Date.now()
  };
}
```

---

### `/src/storage.js`

```js
import fs from "fs";

export function loadSignals() {
  try { return JSON.parse(fs.readFileSync("./data/active_signals.json")); }
  catch { return []; }
}

export function saveSignals(list) {
  fs.writeFileSync("./data/active_signals.json", JSON.stringify(list,null,2));
}
```

---

# Next Step

Perfect â€” **DilutionHunter** is a killer name.

Below is everything you can append directly to your **README.md** so the repo is instantly useful, well-structured, and clear to anyone (and Copilot).

This includes:

* Summary introduction
* Features list
* Architecture diagram
* GitHub Actions workflows
* Next steps

You can paste **as-is**.

---

## ğŸš€ **DilutionHunter**

Automated market-wide scanner that detects parabolic runners at risk of equity dilution, generates AI-written thesis threads, and posts signals + performance tracking updates to X (Twitter).

---

## ğŸ”¥ What It Does

âœ” Scans entire U.S. stock market 1â€“3x/day via GitHub Actions
âœ” Filters for 200â€“300%+ weekly runners (**momentum blowout signals**)
âœ” Detects *first red day*, volume fade, exhaustion candles
âœ” Pulls balance sheet data (cash vs debt) â†’ evaluates need to raise capital
âœ” Monitors SEC/FMP offering data to identify probable dilution events
âœ” Auto-generates a tweet thread summarizing thesis via OpenAI
âœ” Posts breakdown to X automatically using Premium X API
âœ” Stores only actionable tickers for tracking (**no full DB needed**)
âœ” Each day â†’ updates performance + tweets results

No servers. No hosting bill.
Just GitHub Actions + JSON state files + API keys.

---

## ğŸ§  Concept Overview

```
US Market â†’ Filter Parabolic Runners â†’ Check Cash/Debt â†’ 
Look For Equity Offering â†’ Confirm Red Candle Signal â†’ 
Auto-Tweet Thesis â†’ Track P/L Daily
```

**If all conditions fire â†’ it's a dilution short candidate.**

---

## ğŸ“‚ Project Structure

```bash
DilutionHunter/
â”‚
â”œâ”€ /src/
â”‚   â”œâ”€ scanner.js              # scans entire market, finds setups
â”‚   â”œâ”€ scoreEngine.js          # evaluation logic + signal scoring
â”‚   â”œâ”€ storage.js              # read/write JSON state
â”‚   â”œâ”€ postTweet.js            # AI analysis + threading to X
â”‚   â”œâ”€ updatePerformance.js    # daily follow-up tracking
â”‚   â””â”€ vendors/fmp.js          # FMP API wrappers (data fetchers)
â”‚
â”œâ”€ /data/
â”‚   â”œâ”€ active_signals.json         # only stores tickers we are tracking
â”‚   â””â”€ performance_history.json    # daily price logs for triggered setups
â”‚
â”œâ”€ /docs/
â”‚   â”œâ”€ architecture.md
â”‚   â””â”€ system.md (Copilot Master Prompt)
â”‚
â””â”€ /.github/workflows/scan.yml     # GitHub Actions automation
```

---

## âš™ `.github/workflows/scan.yml`

Paste & start running immediately:

```yaml
name: DilutionHunter Scan

on:
  schedule:
    - cron: "0 */8 * * *"  # every 8 hours â€” 3 scans/day
  workflow_dispatch: {}    # manual run button

jobs:
  run_scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Install Node
        uses: actions/setup-node@v3
        with:
          node-version: 18

      - name: Install Dependencies
        run: npm install

      - name: Run Scanner
        run: node src/scanner.js

      - name: Commit Updates
        run: |
          git config --global user.name "DilutionHunter Bot"
          git config --global user.email "bot@dilutionhunter"
          git add data/*.json
          git commit -m "update signals/performance [CI]" || echo "no changes"
          git push
```

---

## ğŸ”‘ Required ENV Variables

Create a `.env` (and *never commit it*):

```
FMP_API_KEY=
OPENAI_API_KEY=
TWITTER_API_KEY=
TWITTER_API_SECRET=
TWITTER_ACCESS_TOKEN=
TWITTER_ACCESS_SECRET=
```

Add this to `.gitignore`:

```
.env
data/*.backup.json
```

---

## ğŸ TODO: Next Implementation Steps

| Step                              | Status                            |
| --------------------------------- | --------------------------------- |
| FMP integration for scanning      | â³ Next to implement               |
| Trigger scoring + filtering logic | â³ Add red-day + volume fade rules |
| AI-generated threads              | â³ via `postTweet.js`              |
| Chart image generator             | ğŸ”¥ optional but recommended       |
| Daily P/L follow-ups              | ğŸ”¥ completes the system           |

---

### Data Output Contract â€” Must Follow This Shape
These structures tell Copilot exactly how data must be formatted and stored.

#### `active_signals.json`
Stores all currently active dilution candidates that have triggered the scanner.
Each new setup is appended as one full object in this structure.
{
  "ticker": "TTOO",
  "trigger_date": "2025-02-14",
  "entry_price": 4.72,
  "weekly_gain_pct": 312,
  "first_red_day": true,
  "volume_fade": true,
  "cash": 1200000,
  "debt": 7500000,
  "offering_size_estimated": "20-40M ATM",
  "offering_source": "FMP-equity-offering-by-cik",
  "dilution_risk_score": 0.88,
  "reason": "parabolic run + low cash + offering active",
  "tweet_id": null,
  "notes": {}
}
â†’ Represents one stock that meets criteria and should be tracked going forward.

#### `performance_history.json`
Tracks the price performance of previously triggered tickers daily.
Used to generate follow-up tweets to show if thesis plays out.
{
  "TTOO": [
    { "date": "2025-02-15", "close": 4.11 },
    { "date": "2025-02-16", "close": 3.29 },
    { "date": "2025-02-17", "close": 2.44 }
  ]
}
â†’ Keys = tickers, values = list of daily closes for P/L tracking.

### Performance Scoring Formula Reference
Used to rank conviction and reduce false signals before tweeting.
dilution_risk_score = weighted(
  weekly_gain_pct,
  cash_vs_debt_ratio,
  offering_size_relative_to_mcap,
  volume_drop_strength,
  candle_reversal_strength
)
// scale: 0â€“1
â†’ 1.00 = extremely high dilution risk / short candidate.
â†’ 0.20 = weak or no thesis, donâ€™t tweet.

### Security Notice
ğŸš¨ IMPORTANT â€” DO NOT COMMIT `.env` OR API KEYS  
If `.env` is ever committed publicly â†’ revoke keys immediately.
â†’ This keeps your repo safe to make public and protects your API access.
